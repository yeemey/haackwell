{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xarray\n",
      "  Downloading xarray-0.9.6-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 2.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.15.0 in /opt/conda/lib/python3.5/site-packages (from xarray)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.5/site-packages (from xarray)\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.5/site-packages (from pandas>=0.15.0->xarray)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.5/site-packages (from pandas>=0.15.0->xarray)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.5/site-packages (from python-dateutil>=2->pandas>=0.15.0->xarray)\n",
      "Installing collected packages: xarray\n",
      "Successfully installed xarray-0.9.6\n",
      "Collecting plotly\n",
      "  Downloading plotly-2.0.15.tar.gz (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 773kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.0.6 in /opt/conda/lib/python3.5/site-packages (from plotly)\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/lib/python3.5/site-packages (from plotly)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.5/site-packages (from plotly)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.5/site-packages (from plotly)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.5/site-packages (from plotly)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.5/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/lib/python3.5/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.5/site-packages (from nbformat>=4.2->plotly)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.5/site-packages (from nbformat>=4.2->plotly)\n",
      "Building wheels for collected packages: plotly\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/c9/c4/00/a80b040dd8c9301d29f7153881c96edf1cd8561977ec440941\n",
      "Successfully built plotly\n",
      "Installing collected packages: plotly\n",
      "Successfully installed plotly-2.0.15\n",
      "Collecting geopandas\n",
      "  Downloading geopandas-0.3.0-py2.py3-none-any.whl (888kB)\n",
      "\u001b[K    100% |████████████████████████████████| 890kB 784kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting descartes (from geopandas)\n",
      "  Downloading descartes-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: pyproj in /opt/conda/lib/python3.5/site-packages (from geopandas)\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.5/site-packages (from geopandas)\n",
      "Requirement already satisfied: fiona in /opt/conda/lib/python3.5/site-packages (from geopandas)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.5/site-packages (from geopandas)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.5/site-packages (from descartes->geopandas)\n",
      "Requirement already satisfied: cligj in /opt/conda/lib/python3.5/site-packages (from fiona->geopandas)\n",
      "Requirement already satisfied: click-plugins in /opt/conda/lib/python3.5/site-packages (from fiona->geopandas)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.5/site-packages (from fiona->geopandas)\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.5/site-packages (from fiona->geopandas)\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.5/site-packages (from pandas->geopandas)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.5/site-packages (from pandas->geopandas)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /opt/conda/lib/python3.5/site-packages (from pandas->geopandas)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.5/site-packages/cycler-0.10.0-py3.5.egg (from matplotlib->descartes->geopandas)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /opt/conda/lib/python3.5/site-packages (from matplotlib->descartes->geopandas)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.5/site-packages (from cligj->fiona->geopandas)\n",
      "Installing collected packages: descartes, geopandas\n",
      "Successfully installed descartes-1.1.0 geopandas-0.3.0\n",
      "Collecting rasterstats\n",
      "  Downloading rasterstats-0.12.0-py2.py3-none-any.whl\n",
      "Collecting simplejson (from rasterstats)\n",
      "  Downloading simplejson-3.11.1.tar.gz (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 1.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fiona in /opt/conda/lib/python3.5/site-packages (from rasterstats)\n",
      "Requirement already satisfied: cligj>=0.4 in /opt/conda/lib/python3.5/site-packages (from rasterstats)\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.5/site-packages (from rasterstats)\n",
      "Collecting rasterio>=0.27 (from rasterstats)\n",
      "  Downloading rasterio-0.36.0.tar.gz (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 652kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9 in /opt/conda/lib/python3.5/site-packages (from rasterstats)\n",
      "Requirement already satisfied: click-plugins in /opt/conda/lib/python3.5/site-packages (from fiona->rasterstats)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.5/site-packages (from fiona->rasterstats)\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.5/site-packages (from fiona->rasterstats)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.5/site-packages (from cligj>=0.4->rasterstats)\n",
      "Collecting affine (from rasterio>=0.27->rasterstats)\n",
      "  Downloading affine-2.1.0-py3-none-any.whl\n",
      "Collecting snuggs (from rasterio>=0.27->rasterstats)\n",
      "  Downloading snuggs-1.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.5/site-packages (from snuggs->rasterio>=0.27->rasterstats)\n",
      "Building wheels for collected packages: simplejson, rasterio\n",
      "  Running setup.py bdist_wheel for simplejson ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/bf/0a/27/5d5e337ed16a175fd483a8c1486b4343ea2632be7ac57bad5d\n",
      "  Running setup.py bdist_wheel for rasterio ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/7d/a3/7b/fb9aa2a4bb68266e478ea9db3ee4794569f1082b89331f1b9c\n",
      "Successfully built simplejson rasterio\n",
      "Installing collected packages: simplejson, affine, snuggs, rasterio, rasterstats\n",
      "Successfully installed affine-2.1.0 rasterio-0.36.0 rasterstats-0.12.0 simplejson-3.11.1 snuggs-1.4.1\n",
      "Requirement already satisfied: affine in /opt/conda/lib/python3.5/site-packages\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install xarray\n",
    "!python3 -m pip install plotly\n",
    "!python3 -m pip install geopandas\n",
    "!python3 -m pip install rasterstats\n",
    "!python3 -m pip install affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%qtconsole\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import plotly.plotly as py\n",
    "py.sign_in('ctasich', 'fpoe1n01ek')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from utilities import hydroshare\n",
    "import rasterstats as rs\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "\n",
    "import glob # check folder for similar file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load Data\n",
    "\n",
    "# GRACE data\n",
    "nc = 'https://opendap.jpl.nasa.gov:443/opendap/GeodeticsGravity/tellus/L3/mascon/RL05/JPL/CRI/netcdf/GRCTellus.JPL.200204_201701.GLO.RL05M_1.MSCNv02CRIv02.nc'\n",
    "grace = xr.open_dataset(nc)\n",
    "\n",
    "# Well data\n",
    "#csv = 'https://www.hydroshare.org/django_irods/download/d3659dcf575d4090801a74d1ce096d7c/data/contents/WPDx_Well_Function_Upd_151224_xy161117.csv'\n",
    "csv = os.path.join('/home/jovyan/work/notebooks/haackwell','dat','well-data-2001-2015-no-rainwater.csv')\n",
    "wells = pd.read_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the following system variables:\n",
      "   HS_USR_NAME = jphuong\n",
      "   HS_RES_ID = bf7b1abb7ec14599b644116d20efebd5\n",
      "   HS_RES_TYPE = compositeresource\n",
      "   JUPYTER_HUB_IP = jupyter.cuahsi.org\n",
      "\n",
      "These can be accessed using the following command: \n",
      "   os.environ[key]\n",
      "\n",
      "   (e.g.)\n",
      "   os.environ[\"HS_USR_NAME\"]  => jphuong\n",
      "\n",
      "The hs_utils library requires a secure connection to your HydroShare account.\n",
      "Enter the HydroShare password for user 'jphuong': ········\n",
      "Successfully established a connection with HydroShare\n",
      "This resource already exists in your userspace.\n",
      "Would you like to overwrite this data [Y/n]? y\n",
      "Downloading Resource \\"
     ]
    }
   ],
   "source": [
    "hs=hydroshare.hydroshare()\n",
    "hs.getResourceFromHydroShare('bf7b1abb7ec14599b644116d20efebd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the Kenyan shapefile path\n",
    "kenp = hs.content['KEN_adm1.shp']\n",
    "print(kenp)\n",
    "\n",
    "# map the parent directory for the shapefiles\n",
    "HW2017 = os.path.join(kenp, os.pardir)\n",
    "print(HW2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the shapefile for kenya\n",
    "# country boundary\n",
    "Ken=gpd.read_file(kenp)\n",
    "Ken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ken.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read many shape file in the folder\n",
    "gdfs = {} # load the empty dictionary \n",
    "\n",
    "# loop through the adm2 shapfile\n",
    "for fname in glob.glob(os.path.abspath(os.path.join(HW2017,'*_adm2.shp'))):\n",
    "    print(os.path.basename(fname).split('.')[0])\n",
    "    gdfs[os.path.basename(fname).split('.')[0]] = gpd.read_file(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile each dataframe into a single, long dataframe\n",
    "dfs_all = pd.concat([gdf for gdf in gdfs.values()])\n",
    "\n",
    "# convert the geodataframe to a epsg:4326 projection\n",
    "gdfs_all = gpd.GeoDataFrame(dfs_all, crs={'init': 'epsg:4326'})\n",
    "\n",
    "# print the gdfs geometry\n",
    "print(len(gdfs_all['geometry']))\n",
    "gdfs_all['geometry'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at all annotations available for each adm2 shape\n",
    "gdfs_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider the NAME_1 for each adm2 polygon\n",
    "gdfs_all.groupby('NAME_1').NAME_1.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract the centroids for the adm2 polygons\n",
    "centroidseries = gdfs_all['geometry'].centroid\n",
    "\n",
    "# convert the centroids into a geodataframe\n",
    "gdf = gpd.GeoDataFrame(centroidseries.reset_index()).rename(columns={'index':'shape_index', 0:'adm2_centroid'})\n",
    "gdf['NAME_1'] = list(gdfs_all['NAME_1'])\n",
    "\n",
    "# extract the longitude and latitude coordinate values into two columns\n",
    "gdf['LONG'] = gdf.adm2_centroid.map(lambda x: x.x)\n",
    "gdf['LAT'] = gdf.adm2_centroid.map(lambda x: x.y)\n",
    "gdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the raster file (here use grace as example)\n",
    "grace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thickness_variable\n",
    "gw = grace['lwe_thickness']\n",
    "gw.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dictionary containing the indices and their corresponding datapoint\n",
    "pgw=dict()\n",
    "\n",
    "for ind, eachrow in gdf.iterrows():\n",
    "    pgw[ind] = gw.sel(lon=eachrow['LONG'], lat=eachrow['LAT'], method='nearest')\n",
    "    print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a sample of the lwe_thickness xarray matrix\n",
    "pgw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the geometry of the country admin (a list of shapes)\n",
    "shapes = [(shape, n) for n, shape in enumerate(Ken.geometry)]\n",
    "shapes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the well coordinate\n",
    "wells['coord'] = wells.apply(lambda x: Point(x['LONG_DD'], x['LAT_DD']), axis=1)\n",
    "wells.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the annotations for a single record\n",
    "wells.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each adm2 shape\n",
    "#for eachshape in shapes:\n",
    "#    # if the well intersects the polygon region\n",
    "#    if eachshape[0].intersects(wells['coord']):\n",
    "#        wells['adm2_title']=\n",
    "#        continue\n",
    "#    continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the transform and rasterize in xarray\n",
    "def transform_from_latlon(lat, lon):\n",
    "    lat = np.asarray(lat)\n",
    "    lon = np.asarray(lon)\n",
    "    trans = Affine.translation(lon[0], lat[0])\n",
    "    scale = Affine.scale(lon[1] - lon[0], lat[1] - lat[0])\n",
    "    return trans * scale\n",
    "\n",
    "def rasterize(shapes, coords, fill=np.nan, **kwargs):\n",
    "    \"\"\"Rasterize a list of (geometry, fill_value) tuples onto the given\n",
    "    xarray coordinates. This only works for 1d latitude and longitude arrays.\n",
    "    \"\"\"\n",
    "    transform = transform_from_latlon(coords['lat'], coords['lon'])\n",
    "    out_shape = (len(coords['lat']), len(coords['lon']))\n",
    "    raster = features.rasterize(shapes, out_shape=out_shape, fill=fill, transform=transform, dtype=float, **kwargs)\n",
    "    return xr.DataArray(raster, dims=('lat', 'lon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## problematic operation ##\n",
    "\n",
    "# mask the xarray based on the polygon\n",
    "gw['countries'] = rasterize(shapes, gw.coords)\n",
    "gw['countries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grace_time_series\n",
    "# .lwe_thickness\n",
    "time_series=grace.sel(time=slice('2002-04-16', '2016-12-31'), lat=75.25, lon=180.25)\n",
    "time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the raster statistic to get the mean of GRACE values for each country \n",
    "# need to figure out the file path problem\n",
    "\n",
    "# convert the xrray to raster\n",
    "\n",
    "# file path\n",
    "#ppt_july_tif_pth = os.path.join(nc, 'prism_precipitation_july_climatology.tif')\n",
    "\n",
    "zonal_grace_af_gjson = rs.zonal_stats(gdfs['TZA_adm2'], grace, prefix='grace_', geojson_out=True)\n",
    "\n",
    "zonal_faf_gdf = gpd.GeoDataFrame.from_features(zonal_grace_af_gjson)\n",
    "zonal_faf_gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Preprocess data\n",
    "\n",
    "## Wells\n",
    "wells['color'] = np.where(wells['FUNC']=='Yes', '#2ECC71', '#E74C3C')\n",
    "\n",
    "## GRACE\n",
    "rmap = grace['lwe_thickness'][0,:,:]\n",
    "\n",
    "# Extract Lat/Lon Metadata\n",
    "lat_min = grace.geospatial_lat_min\n",
    "lat_max = grace.geospatial_lat_max\n",
    "lat_res = float(grace.geospatial_lat_resolution[0:3])\n",
    "\n",
    "lon_min = grace.geospatial_lon_min\n",
    "lon_max = grace.geospatial_lon_max\n",
    "lon_res = float(grace.geospatial_lon_resolution[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot GRACE data\n",
    "\n",
    "# Build grid\n",
    "lon_g = np.arange(lon_min,lon_max+lon_res,lon_res)\n",
    "lat_g = np.arange(lat_min,lat_max+lat_res,lat_res)\n",
    "x,y = np.meshgrid(lon_g[:], lat_g[:])\n",
    "\n",
    "# Plot Fig\n",
    "plt.figure(figsize=(20,10))\n",
    "m = Basemap(projection='moll',llcrnrlat=-87,urcrnrlat=81,lon_0=0,\\\n",
    "            llcrnrlon=0,urcrnrlon=360,resolution='c')\n",
    "# draw parallels and meridians.\n",
    "parallels = np.arange(-89.75,89.75,30.)\n",
    "# Label the meridians and parallels\n",
    "m.drawparallels(parallels,labels=[False,True,True,False])\n",
    "# Draw Meridians and Labels\n",
    "meridians = np.arange(-180.,181.,30.)\n",
    "m.drawmeridians(meridians)\n",
    "m.drawmapboundary(fill_color='white')\n",
    "\n",
    "ax = plt.gca()\n",
    "masked_array = np.ma.array(rmap, mask=np.isnan(rmap))\n",
    "cmap = matplotlib.cm.jet\n",
    "cmap.set_bad('white',1.0)\n",
    "\n",
    "im1 = m.pcolormesh(x,y,rmap,shading='flat',latlon=True);\n",
    "im2 = m.pcolormesh(x,y,masked_array,shading='flat',latlon=True)\n",
    "m.drawcoastlines();\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Water thickness equivalent (cm)')\n",
    "plt.title('GRACE initial measurement',size=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot well data in plotly\n",
    "\n",
    "data = [ dict(\n",
    "    lat = wells.LAT_DD,\n",
    "    lon = wells.LONG_DD,\n",
    "    marker = dict(\n",
    "        color = wells.color.tolist(),\n",
    "        opacity = 0.7,\n",
    "        size = 2,                \n",
    "    ),\n",
    "    type = 'scattergeo'\n",
    ") ]\n",
    "\n",
    "layout = dict(\n",
    "    geo = dict(showland = True,\n",
    "        landcolor = \"rgb(212, 212, 212)\",\n",
    "        subunitcolor = \"rgb(255, 255, 255)\",\n",
    "        countrycolor = \"rgb(255, 255, 255)\",\n",
    "        showlakes = True,\n",
    "        lakecolor = \"rgb(255, 255, 255)\",\n",
    "        showsubunits = True,\n",
    "        showcountries = True,\n",
    "        resolution = 10,\n",
    "        projection = dict(\n",
    "            type = 'utm'),\n",
    "        lonaxis = dict(\n",
    "            showgrid = True,\n",
    "            gridwidth = 0.5,\n",
    "            range= [ -20, 80 ],\n",
    "            dtick = 5\n",
    "        ),\n",
    "        lataxis = dict (\n",
    "            showgrid = True,\n",
    "            gridwidth = 0.5,\n",
    "            range= [ -20, 40 ],\n",
    "            dtick = 5\n",
    "        )\n",
    "    ),\n",
    "    title = 'Wells from WPDx',\n",
    ")\n",
    "fig = { 'data':data, 'layout':layout }\n",
    "py.iplot(fig, filename='wells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code that subselects regions of interest. This is for all of Africa, but will be used later to get individual time series\n",
    "\n",
    "data = xr.open_dataset('https://opendap.jpl.nasa.gov:443/opendap/GeodeticsGravity/tellus/L3/mascon/RL05/JPL/CRI/netcdf/GRCTellus.JPL.200204_201701.GLO.RL05M_1.MSCNv02CRIv02.nc')\n",
    "af = xr.concat( [data['lwe_thickness'].sel(lat=slice(-37.75,37.75)).sel(lon=slice(340.25,359.75)),\n",
    "                  data['lwe_thickness'].sel(lat=slice(-37.75,37.75)).sel(lon=slice(0.25,50.75))],\n",
    "                  dim='lon')\n",
    "\n",
    "lonaf = xr.concat( [data['lon'].sel(lon=slice(340.25,359.75)),\n",
    "                  data['lon'].sel(lon=slice(0.25,50.75))],\n",
    "                  dim='lon')\n",
    "\n",
    "lataf = data['lat'].sel(lat=slice(-37.75,37.75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find nearest grid locations for all data\n",
    "# lon_g and lat_g are the lons and lats of the gridded products, respectively\n",
    "# nb this is only for Africa for now! Change things in the previous cell if you want to deal with the global GRACE dataset.\n",
    "\n",
    "lon_g = lonaf\n",
    "lat_g = lataf\n",
    "\n",
    "xRes = np.median(np.diff(lon_g))\n",
    "yRes = np.median(np.diff(lat_g))\n",
    "\n",
    "# Define grid box centers\n",
    "lon_c = lon_g[:-1]+xRes/2\n",
    "lat_c = lat_g[:-1]+yRes/2\n",
    "\n",
    "# Define a new metadata file that has grid coordinates for this resolution choice\n",
    "wg = wells\n",
    "\n",
    "wg.loc[:,'grid_lat'] = np.nan\n",
    "wg.loc[:,'grid_lon'] = np.nan\n",
    "wg.loc[:,'grace_mean'] = np.nan\n",
    "wg.loc[:,'grace_std'] = np.nan\n",
    "wg.loc[:,'grace_at_rpt_date'] = np.nan\n",
    "\n",
    "## Determine grid_lat and grid_lon for every record\n",
    "\n",
    "for index, row in wg.iterrows():\n",
    "    lon_s = row[u'LONG_DD']\n",
    "    lat_s = row[u'LAT_DD']\n",
    "    # correct for wrapping\n",
    "    if lon_s<0:\n",
    "        lon_s = 360+lon_s\n",
    "    glat = lat_g.values[np.argmin(np.abs(lat_c.values-lat_s))]\n",
    "    glon = lon_g.values[np.argmin(np.abs(lon_c.values-lon_s))]\n",
    "    wg.set_value(index,'grid_lat',glat)\n",
    "    wg.set_value(index,'grid_lon',glon)\n",
    "\n",
    "# Get all unique grid_lat and grid_lon pairs. Don't totally understand this bit of magic...\n",
    "allpairs = wg[['grid_lat', 'grid_lon']].values\n",
    "upairs = np.array(list(set(tuple(p) for p in allpairs)))\n",
    "\n",
    "# GRACE at well locations. sel_points is necessary to get coordinate pairs.\n",
    "wellG = data['lwe_thickness'].sel_points(lat=upairs[:,0],lon=upairs[:,1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop through the dataframe again and compute stats!\n",
    "\n",
    "for index, row in wg.iterrows():\n",
    "    glat = row[u'grid_lat']\n",
    "    glon = row[u'grid_lon']\n",
    "\n",
    "    # get the corresponding point\n",
    "    pt = wellG[(wellG['lat']==glat).values & (wellG['lon']==glon).values].points.values\n",
    "    allhere = wellG.sel(points=pt)\n",
    "    wg.set_value(index,'grace_mean',np.mean(allhere.values))\n",
    "    wg.set_value(index,'grace_std',np.std(allhere.values))\n",
    "\n",
    "    dda = row[u'RPT_DATE']\n",
    "    dgr = allhere['time'].values\n",
    "    best_gr_ind = np.argmin(np.abs(pd.to_datetime(dgr)-pd.to_datetime(dda)))\n",
    "\n",
    "    wg.set_value(index,'grace_at_rpt_date',np.squeeze(allhere.values)[best_gr_ind])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look\n",
    "wg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there any relationship between GRACE and the well data?\n",
    "\n",
    "# 1. Compare g_mean to g_rpt. Make 2 histograms, one for working and one for not. Anything there?\n",
    "\n",
    "\n",
    "# differences between mean and report time GRACE values\n",
    "d_mean_rpt_yes = wg[wg['FUNC']=='Yes' ]['grace_at_rpt_date']-wg[wg['FUNC']=='Yes']['grace_mean']\n",
    "d_mean_rpt_no  = wg[wg['FUNC']=='No'  ]['grace_at_rpt_date']-wg[wg['FUNC']=='No' ]['grace_mean']\n",
    "\n",
    "bins = np.arange(-40,40)\n",
    "\n",
    "plt.hist(d_mean_rpt_yes,bins=bins,alpha=0.5,label='Not functioning')\n",
    "plt.hist(d_mean_rpt_no ,bins=bins,alpha=0.5,label='Functioning')\n",
    "plt.ylabel('Number of records')\n",
    "plt.title('GRACE LWE at report dates for African sites minus 2002-2016 mean',size=12)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Anomaly in liquid water equivalent (cm)')\n",
    "plt.show()\n",
    "\n",
    "# 2. Histograms of g_std for working and not. Any difference?\n",
    "\n",
    "d_std_yes = wg[wg['FUNC']=='Yes' ]['grace_std']\n",
    "d_std_no  = wg[wg['FUNC']=='No'  ]['grace_std']\n",
    "\n",
    "bins = np.arange(0,30)\n",
    "\n",
    "plt.hist(d_std_yes,bins=bins,alpha=0.5,label='Not functioning')\n",
    "plt.hist(d_std_no ,bins=bins,alpha=0.5,label='Functioning')\n",
    "plt.ylabel('Number of records')\n",
    "plt.title('GRACE standard deviation of LWE at African sites, 2002-2016')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Liquid water equivalent (cm)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
